# CA04
This project compares the performance of four models (Random Forest, AdaBoost, Gradient Boost, XGBoost) in predicting income categories based on demographic attributes based on accuracy, AUC, and number of estimators. It encompasses data preprocessing, model training, hyperparameter tuning, and prediction.

### Installation
1. Clone the repository.
2. Install dependencies using pip install -r requirements.txt.

### Usage
1. Explore Jupyter Notebooks in the notebooks/ directory.
2. Follow instructions in the notebooks for analysis, preprocessing, training, tuning, and prediction.

### Results
#### Accuracy:
  Random Forest: 0.838953
  AdaBoost: 0.845341
  Gradient Boost: 0.846570
  XGBoost: 0.843867
  Gradient Boost p[erformed the bets in terms of accuracy.

#### AUC:
  Random Forest: 0.748384
  AdaBoost: 0.748884
  Gradient Boost: 0.754896
  XGBoost: 0.75707
  XGBoost performed the best for AUC.


### The project utilizes the following Python libraries:
1. pandas: Data manipulation and analysis
2. numpy: Numerical computing
3. matplotlib: Data visualization
4. scikit-learn: Machine learning algorithms and tools
These libraries are essential for tasks such as data preprocessing, model training, hyperparameter tuning, and result visualization.
